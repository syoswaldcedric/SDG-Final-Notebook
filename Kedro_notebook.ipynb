{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fac3797",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103dbfe5",
   "metadata": {},
   "source": [
    "Not sure we will need all these libraries for kedro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0ddf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules for data science and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 180 # Quality of all figures in notebook\n",
    "\n",
    "# imports for Natural Language  Processing\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import time\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from html.parser import HTMLParser\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import emoji\n",
    "from emoji import emojize\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "# Classification Models\n",
    "import xgboost\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "# Performance Evaluation\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from pipelinehelper import PipelineHelper\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Import library for train test split\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "# Wordcloud\n",
    "from PIL import Image\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Resampling techniques\n",
    "from collections import Counter \n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474976f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import texthero as hero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04a4820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Adetunji\n",
      "[nltk_data]     Emmanuel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c87029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Data read_csvtion, importing `csv` file only\n",
    "    Args:\n",
    "        path: string like `file` address in the directory\n",
    "    Return:\n",
    "        df: (Dataframe) output imported csv file as pandas Dataframe\n",
    "    \"\"\"\n",
    "    train_df = pd.read_csv(path, sep='\\t')\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ec3f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sdg</th>\n",
       "      <th>labels_negative</th>\n",
       "      <th>labels_positive</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.6027/9789289342698-7-en</td>\n",
       "      <td>00021941702cd84171ff33962197ca1f</td>\n",
       "      <td>From a gender perspective, Paulgaard points ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.18356/eca72908-en</td>\n",
       "      <td>00028349a7f9b2485ff344ae44ccfd6b</td>\n",
       "      <td>Labour legislation regulates maximum working h...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1787/9789264289062-4-en</td>\n",
       "      <td>0004eb64f96e1620cd852603d9cbe4d4</td>\n",
       "      <td>The average figure also masks large difference...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1787/5k9b7bn5qzvd-en</td>\n",
       "      <td>0006a887475ccfa5a7f5f51d4ac83d02</td>\n",
       "      <td>The extent to which they are akin to corruptio...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1787/9789264258211-6-en</td>\n",
       "      <td>0006d6e7593776abbdf4a6f985ea6d95</td>\n",
       "      <td>A region reporting a higher rate will not earn...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          doi                           text_id  \\\n",
       "0  10.6027/9789289342698-7-en  00021941702cd84171ff33962197ca1f   \n",
       "1        10.18356/eca72908-en  00028349a7f9b2485ff344ae44ccfd6b   \n",
       "2  10.1787/9789264289062-4-en  0004eb64f96e1620cd852603d9cbe4d4   \n",
       "3     10.1787/5k9b7bn5qzvd-en  0006a887475ccfa5a7f5f51d4ac83d02   \n",
       "4  10.1787/9789264258211-6-en  0006d6e7593776abbdf4a6f985ea6d95   \n",
       "\n",
       "                                                text  sdg  labels_negative  \\\n",
       "0  From a gender perspective, Paulgaard points ou...    5                1   \n",
       "1  Labour legislation regulates maximum working h...   11                2   \n",
       "2  The average figure also masks large difference...    3                1   \n",
       "3  The extent to which they are akin to corruptio...    3                1   \n",
       "4  A region reporting a higher rate will not earn...    3                2   \n",
       "\n",
       "   labels_positive  agreement  \n",
       "0                7   0.750000  \n",
       "1                1   0.333333  \n",
       "2                6   0.714286  \n",
       "3                2   0.333333  \n",
       "4                2   0.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = import_dataset('osdg-community-dataset-v21-09-30.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad2d1d",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "567e9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_agreement(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    This function takes in a dataframe and filters out the rows with negative label higher than positive label,\n",
    "    and have an agreement score less than 0.4\n",
    "    \n",
    "    Args: \n",
    "        Source training data\n",
    "        \n",
    "    Returns:\n",
    "        Filtered data that has high positive community agreement with SDG labels\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    data = data.loc[(data['labels_negative'] < data['labels_positive']) & (data['agreement'] >= 0.4)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37cb66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(df: pd.DataFrame) ->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    df1 = df.dropna(subset=['text'])\n",
    "    df2 = df1.dropna(subset=['sdg'])\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8229dda",
   "metadata": {},
   "source": [
    "#### Secondary functions used to pre-process the text data\n",
    "\n",
    "Can we create more functions that clean data in a more specialized way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde59bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_article(text: str) -> str:\n",
    "    \n",
    "    \"\"\"Converts apostrophe suffixes to words, replace webpage links with url, annotate \n",
    "    hashtags and mentions, remove a selection of punctuation, and convert all words to lower case.\n",
    "    Args:\n",
    "        text: 'text' article or sentence to be cleaned\n",
    "    Returns:\n",
    "        clean_text: clean text rid of noise \n",
    "    \"\"\"\n",
    "    def remove_extras(post):\n",
    "        punc_numbers = string.punctuation + '0123456789'\n",
    "        return ''.join([l for l in post if l not in punc_numbers])\n",
    "    #Lower case\n",
    "    text = text.lower()\n",
    "    #Removal of Punctuation\n",
    "    text = remove_extras(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "015743a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lemmatize(text: str) -> str:\n",
    "    \"\"\"Lemmatize text.\n",
    "    Args:\n",
    "        text (String): sentence containing 'text' to lemmatize (stemming)\n",
    "    Returns:\n",
    "        text (String): sentence with converted 'text' into lemmatized word(s)  \n",
    "    \"\"\"\n",
    "    # removing any form of hyper link(s)\n",
    "    stop_words = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words and len(word)>2]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bfd2bb",
   "metadata": {},
   "source": [
    "#### Primary function to pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f595fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Preprocess data.\n",
    "    \n",
    "     Args:\n",
    "        data: Full (all columns) training cleaned data according to agreement score\n",
    "        \n",
    "     Returns:\n",
    "        Processed text data as pandas dataframe.\n",
    "        \n",
    "    '''\n",
    "    # removing missing rows in the important columns\n",
    "    data = missing_data(data)\n",
    "    #apply text hero\n",
    "    data['text'] = data['text'].apply(clean_article)\n",
    "    #lemmatize the text\n",
    "    data['text'] = data['text'].apply(_lemmatize)\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4500858a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sdg</th>\n",
       "      <th>labels_negative</th>\n",
       "      <th>labels_positive</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.6027/9789289342698-7-en</td>\n",
       "      <td>00021941702cd84171ff33962197ca1f</td>\n",
       "      <td>From a gender perspective, Paulgaard points ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1787/9789264289062-4-en</td>\n",
       "      <td>0004eb64f96e1620cd852603d9cbe4d4</td>\n",
       "      <td>The average figure also masks large difference...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1787/5js4xfgl4ks0-en</td>\n",
       "      <td>000b54717f2deea5d99055b4c1c2bf5a</td>\n",
       "      <td>These findings are consistent with previous wo...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          doi                           text_id  \\\n",
       "0  10.6027/9789289342698-7-en  00021941702cd84171ff33962197ca1f   \n",
       "2  10.1787/9789264289062-4-en  0004eb64f96e1620cd852603d9cbe4d4   \n",
       "5     10.1787/5js4xfgl4ks0-en  000b54717f2deea5d99055b4c1c2bf5a   \n",
       "\n",
       "                                                text  sdg  labels_negative  \\\n",
       "0  From a gender perspective, Paulgaard points ou...    5                1   \n",
       "2  The average figure also masks large difference...    3                1   \n",
       "5  These findings are consistent with previous wo...   10                2   \n",
       "\n",
       "   labels_positive  agreement  \n",
       "0                7   0.750000  \n",
       "2                6   0.714286  \n",
       "5                5   0.428571  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = clean_agreement(data)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed9f286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sdg</th>\n",
       "      <th>labels_negative</th>\n",
       "      <th>labels_positive</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.6027/9789289342698-7-en</td>\n",
       "      <td>00021941702cd84171ff33962197ca1f</td>\n",
       "      <td>gender perspective paulgaard point labour mark...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1787/9789264289062-4-en</td>\n",
       "      <td>0004eb64f96e1620cd852603d9cbe4d4</td>\n",
       "      <td>average figure also mask large difference acro...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1787/5js4xfgl4ks0-en</td>\n",
       "      <td>000b54717f2deea5d99055b4c1c2bf5a</td>\n",
       "      <td>finding consistent previous work examined diff...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          doi                           text_id  \\\n",
       "0  10.6027/9789289342698-7-en  00021941702cd84171ff33962197ca1f   \n",
       "2  10.1787/9789264289062-4-en  0004eb64f96e1620cd852603d9cbe4d4   \n",
       "5     10.1787/5js4xfgl4ks0-en  000b54717f2deea5d99055b4c1c2bf5a   \n",
       "\n",
       "                                                text  sdg  labels_negative  \\\n",
       "0  gender perspective paulgaard point labour mark...    5                1   \n",
       "2  average figure also mask large difference acro...    3                1   \n",
       "5  finding consistent previous work examined diff...   10                2   \n",
       "\n",
       "   labels_positive  agreement  \n",
       "0                7   0.750000  \n",
       "2                6   0.714286  \n",
       "5                5   0.428571  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocess_data(data)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab394cd",
   "metadata": {},
   "source": [
    "#### Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d417aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to upscale and balance the dataset\n",
    "def data_balancing(df_input: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Dataset balancing for all target variable to be equal in frequency.\n",
    "    Args:\n",
    "        `df` (DataFrame): pd.Series containing the target variable\n",
    "    Return:\n",
    "        df (DataFrame): dataframe with resample and balance dataset by upscaling.\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    # setting the maximum size for each category in 'sdg'\n",
    "    class_size = int(df.sdg.value_counts().max()) \n",
    "\n",
    "    target_size = df.sdg.value_counts() # getting category name and their size\n",
    "    appended_target = [] # creating an empty list to append all category after resampling\n",
    "\n",
    "    # Creating a for-loop to resample and append to a list\n",
    "    for index, size in target_size.items():\n",
    "        if size < class_size: # setting condition to check if to downsample or upsample\n",
    "            temp_pd = resample(df[df['sdg']==index],\n",
    "                              replace=True, # sample with replacement\n",
    "                              n_samples=class_size, # match number in majority class\n",
    "                              random_state=27)\n",
    "        else:\n",
    "            temp_pd = resample(df[df['sdg']==index],\n",
    "                              replace=False, # sample with replacement (no need to duplicate observations)\n",
    "                              n_samples=class_size, # match number in minority class\n",
    "                              random_state=27)\n",
    "    # Appending each category after resampling\n",
    "        appended_target.append(temp_pd)\n",
    "        \n",
    "    # Creating a new dataframe and viewing\n",
    "    df_resampled = pd.concat(appended_target, axis=0)\n",
    "    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f10138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the dataset to balance each target\n",
    "data = data_balancing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6383c97e",
   "metadata": {},
   "source": [
    "The problem with jupyter notebooks -> How do we know when we have run each cell and in what order did we run each cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166dfe83",
   "metadata": {},
   "source": [
    "# 2. Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49e807d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef969341",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60818562",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bceea2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this dict will be stored in the paramter.yml file in Kedro\n",
    "\n",
    "parameters = {'test_size': 0.2,\n",
    "              'random_state': 42,\n",
    "             'ngram_range_min': 1,\n",
    "              'ngram_range_max': 2,\n",
    "              'max_features': 100000,\n",
    "              'max_iter': 1000,\n",
    "              'C': 1\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "489c297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data: pd.DataFrame, parameters: Dict) -> List:\n",
    "    '''\n",
    "    Splits data into training and test set.\n",
    "    \n",
    "     Args:\n",
    "        data: Source processed data.\n",
    "        parameters: Parameters defined in parameter.yml.\n",
    "    \n",
    "     Returns:\n",
    "        A list containing split data.\n",
    "        \n",
    "    '''\n",
    "    #data = _handle_empty(data) ... what happens if there is missing data? We could create a function for this as well\n",
    "    X = data['text'].values\n",
    "    y = data['sdg'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=parameters['test_size'], \n",
    "                                                        random_state=parameters['random_state'])\n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8acb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data set to train and test set\n",
    "X_train, X_test, y_train, y_test = split_data(data, parameters )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1495ab23",
   "metadata": {},
   "source": [
    "#### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79ee9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(X_train: np.ndarray, X_test: np.ndarray, parameters: Dict) -> List:\n",
    "    '''\n",
    "    Vectorize text column in train and test set.\n",
    "    \n",
    "     Args:\n",
    "        X_train: Training text data.\n",
    "        X_test: Testing text data.\n",
    "        parameters: Parameters defined in parameter.yml.   \n",
    "       \n",
    "     Returns:\n",
    "        A list containing vectorized train and test feature sets. \n",
    "        \n",
    "    '''\n",
    "\n",
    "\n",
    "    #E.g Tfid\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(parameters['ngram_range_min'],\n",
    "                                              parameters['ngram_range_max']),\n",
    "                                 max_features=parameters['max_features'])\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "    return [X_train, X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40a9a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = vectorize_text(X_train, X_test, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc8a2a",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5d0d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train: np.ndarray, y_train: np.ndarray, parameters: Dict) -> LinearSVC:\n",
    "    '''\n",
    "    Train the Linear SVC model.\n",
    "    \n",
    "     Args:\n",
    "        X_train: Vectorized training text data.\n",
    "        y_train: Training data for SDG labels.\n",
    "        parameters: Parameters defined in parameter.yml.\n",
    "        \n",
    "     Returns:\n",
    "        Trained model.\n",
    "        \n",
    "    '''\n",
    "    classifier = LinearSVC(max_iter=parameters['max_iter'], C=parameters['C'],\n",
    "                           random_state=parameters['random_state'])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e0148ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = train_model(X_train,y_train, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cbee3",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47462356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_test: np.ndarray, y_test: np.ndarray, classifier: LinearSVC):\n",
    "    '''\n",
    "    Generate and log classification report for test data.\n",
    "    \n",
    "     Args:\n",
    "        X_test: Vectorized test text data.\n",
    "        y_test: Test data for SDG.\n",
    "        classifier: Trained model.\n",
    "        \n",
    "    '''\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    score = f1_score(y_test, y_pred, average='weighted')\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"Model has an f1 score (weighted) of %.3f on test data.\", score)\n",
    "    #logger.info(classification_report(y_test, y_pred)) \n",
    "    \n",
    "    #in kedro we will not return score, only log what we have done\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebe28efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973020202634326\n"
     ]
    }
   ],
   "source": [
    "score  = evaluate_model(X_test,y_test, classifier )\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ffdfdd",
   "metadata": {},
   "source": [
    "What can you help with?\n",
    "1. Include data balancing\n",
    "2. More and better specialized functions for text pre-processing. We cant see what is happening under text hero\n",
    "3. Create a function that handles missing data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
